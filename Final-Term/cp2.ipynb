{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"15SB-hNgaIY6cZg0BaYKLFCaHfQecFKwx","timestamp":1681628993425}],"authorship_tag":"ABX9TyP1fA86475gsyO0aooPGw0a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yuIMccG03fNq","executionInfo":{"status":"ok","timestamp":1681629058394,"user_tz":-360,"elapsed":23797,"user":{"displayName":"Shahriar Ayon","userId":"02848543209572806117"}},"outputId":"7b4bcab7-43f2-43ea-e419-461cfe87954b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","from tensorflow.keras.callbacks import EarlyStopping\n","import glob as gb\n","import seaborn as sns\n","import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt"],"metadata":{"id":"dGwR24Gf3wHP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IMG_SIZE = 128\n","SEED = 1000\n","BATCH_SIZE = 32\n","\n","TRAIN_DIR = '/content/drive/MyDrive/YuShare/train'\n","TEST_DIR = '/content/drive/MyDrive/YuShare/test'"],"metadata":{"id":"ESzfxdoM32VS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["categories = []\n","class_count = []\n","train_exm = 0\n","for f in os.listdir(TRAIN_DIR):\n","    files = gb.glob(pathname=str(TRAIN_DIR  + '//' + f + '/*.jpg'))\n","    categories.append(f)\n","    class_count.append(len(files))\n","    train_exm += len(files)\n","\n","sns.barplot(x=categories, y=class_count).set_title(\"distribution of train data\")\n","\n","plt.show()\n","print(train_exm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"VZPQ3AqC4O0Y","executionInfo":{"status":"error","timestamp":1681628874924,"user_tz":-360,"elapsed":467,"user":{"displayName":"Shahriar Ayon","userId":"02848543209572806117"}},"outputId":"22bb310a-d8e2-40ee-9ae3-f535302dfa9d"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-6d01fdf1ac8a>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclass_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_exm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DIR\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0;34m'//'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcategories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/YuShare/train'"]}]},{"cell_type":"code","source":["train_gen = ImageDataGenerator(\n","    rotation_range = 30,\n","    width_shift_range = 0.1,\n","    height_shift_range = 0.1,\n","    horizontal_flip = True,\n","    validation_split = 0.2,\n","    preprocessing_function = tf.keras.applications.vgg16.preprocess_input\n","    # dtype = tf.float32\n",")\n","\n","test_gen = ImageDataGenerator(\n","    preprocessing_function = tf.keras.applications.vgg16.preprocess_input\n","    # dtype = tf.float32\n",")"],"metadata":{"id":"RnHvBzKB4S6V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_batch = train_gen.flow_from_directory(\n","    directory=TRAIN_DIR,\n","    target_size = (IMG_SIZE, IMG_SIZE),\n","    batch_size = BATCH_SIZE,\n","    class_mode = 'sparse',\n","    subset = 'training',\n","    seed = SEED\n",")\n","valid_batch = train_gen.flow_from_directory(\n","    directory=TRAIN_DIR,\n","    target_size = (IMG_SIZE, IMG_SIZE),\n","    batch_size = BATCH_SIZE,\n","    class_mode = 'sparse',\n","    subset = 'validation',\n","    seed = SEED\n",")\n","test_batch = test_gen.flow_from_directory(\n","    directory=TEST_DIR,\n","    target_size = (IMG_SIZE, IMG_SIZE),\n","    batch_size = BATCH_SIZE,\n","    class_mode = 'sparse',\n","    seed = SEED\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"LtTJu_Da4Z2v","executionInfo":{"status":"error","timestamp":1681628884180,"user_tz":-360,"elapsed":11,"user":{"displayName":"Shahriar Ayon","userId":"02848543209572806117"}},"outputId":"1aca9a3c-5f85-412c-8bfb-6bb89f9f4969"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-214be022aea1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_batch = train_gen.flow_from_directory(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mclass_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sparse'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1646\u001b[0m                 \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \"\"\"\n\u001b[0;32m-> 1648\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1649\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/YuShare/train'"]}]},{"cell_type":"code","source":["img_shape = (IMG_SIZE, IMG_SIZE) + (3,)\n","base_model = tf.keras.applications.VGG16(input_shape=img_shape, include_top=False,  weights='imagenet')\n","base_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNIKgYh54j9h","executionInfo":{"status":"ok","timestamp":1681628890170,"user_tz":-360,"elapsed":1269,"user":{"displayName":"Shahriar Ayon","userId":"02848543209572806117"}},"outputId":"6712918c-216e-4bc6-c6be-4b4de519cb66"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 0s 0us/step\n","Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n","                                                                 \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["inputs = tf.keras.Input(shape=(IMG_SIZE,IMG_SIZE, 3))\n","x = base_model(inputs, training=False)\n","x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","x = tf.keras.layers.Dense(512, activation='relu')(x)\n","x = tf.keras.layers.Dropout(0.2)(x)\n","x = tf.keras.layers.Dense(256, activation='relu')(x)\n","x = tf.keras.layers.Dropout(0.2)(x)\n","x = tf.keras.layers.Dense(128, activation='relu')(x)\n","x = tf.keras.layers.Dropout(0.2)(x)\n","output = tf.keras.layers.Dense(5, activation='softmax')(x)\n","\n","model = tf.keras.Model(inputs, output)\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BzUyPZGg4m9G","executionInfo":{"status":"ok","timestamp":1681628895296,"user_tz":-360,"elapsed":459,"user":{"displayName":"Shahriar Ayon","userId":"02848543209572806117"}},"outputId":"0b168b55-d821-4304-9e12-89765187cfe5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 128, 128, 3)]     0         \n","                                                                 \n"," vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n","                                                                 \n"," global_average_pooling2d (G  (None, 512)              0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dense (Dense)               (None, 512)               262656    \n","                                                                 \n"," dropout (Dropout)           (None, 512)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 128)               32896     \n","                                                                 \n"," dropout_2 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 5)                 645       \n","                                                                 \n","=================================================================\n","Total params: 15,142,213\n","Trainable params: 15,142,213\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.compile(\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n","    loss= tf.keras.losses.sparse_categorical_crossentropy,\n","    metrics=['accuracy']\n",")"],"metadata":{"id":"ldo_fSKY4wGt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["h = model.fit(\n","    train_batch,\n","    steps_per_epoch = 642 // BATCH_SIZE,\n","    validation_data=valid_batch,\n","    validation_steps=158 // BATCH_SIZE,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"U4IqBm-z40CS","executionInfo":{"status":"error","timestamp":1681628904052,"user_tz":-360,"elapsed":454,"user":{"displayName":"Shahriar Ayon","userId":"02848543209572806117"}},"outputId":"f0a7ee0c-a0c6-4c05-bb2c-da20fb792a66"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-40f40fb6ab05>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m h = model.fit(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m642\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m158\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_batch' is not defined"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"B5wc7IuV3Mr4","executionInfo":{"status":"error","timestamp":1681628907455,"user_tz":-360,"elapsed":463,"user":{"displayName":"Shahriar Ayon","userId":"02848543209572806117"}},"outputId":"baa4700b-1c47-414f-a6be-450332ddb271"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-50d0bff3e907>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Load the VGG16 model with pre-trained weights on ImageNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m base_model = keras.applications.VGG16(\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m    135\u001b[0m         )\n\u001b[1;32m    136\u001b[0m     \u001b[0;31m# Determine proper input shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     input_shape = imagenet_utils.obtain_input_shape(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mdefault_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/applications/imagenet_utils.py\u001b[0m in \u001b[0;36mobtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    406\u001b[0m                     \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                 ) or (input_shape[1] is not None and input_shape[1] < min_size):\n\u001b[0;32m--> 408\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    409\u001b[0m                         \u001b[0;34m\"Input size must be at least \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                         \u001b[0;34mf\"{min_size}x{min_size}; Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input size must be at least 32x32; Received: input_shape=(28, 28, 3)"]}],"source":["import tensorflow as tf\n","from tensorflow import keras\n","\n","# Load the MNIST dataset\n","(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n","\n","# Reshape the data to (28, 28, 1) and convert to float32\n","x_train = x_train.reshape((-1, 28, 28, 1)).astype('float32')\n","x_test = x_test.reshape((-1, 28, 28, 1)).astype('float32')\n","\n","# Normalize the pixel values to the range [0, 1]\n","x_train /= 255.0\n","x_test /= 255.0\n","\n","# Convert the labels to one-hot encoded vectors\n","num_classes = 10\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","# Load the VGG16 model with pre-trained weights on ImageNet\n","base_model = keras.applications.VGG16(\n","    weights='imagenet',\n","    include_top=False,\n","    input_shape=(28, 28, 3))\n","\n","# Freeze the layers of the pre-trained model\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# Add a classifier on top of the VGG16 model\n","model = keras.Sequential([\n","    base_model,\n","    keras.layers.Flatten(),\n","    keras.layers.Dense(256, activation='relu'),\n","    keras.layers.Dropout(0.5),\n","    keras.layers.Dense(num_classes, activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Train the model with frozen weights\n","history_freeze = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"]},{"cell_type":"code","source":["# Unfreeze the last few layers of the pre-trained model\n","for layer in base_model.layers[-4:]:\n","    layer.trainable = True\n","\n","# Recompile the model\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Train the model with fine-tuned weights\n","history_unfreeze = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":623},"id":"gvwQhxCe3a8w","executionInfo":{"status":"error","timestamp":1681628914157,"user_tz":-360,"elapsed":1056,"user":{"displayName":"Shahriar Ayon","userId":"02848543209572806117"}},"outputId":"fcb454c4-32b3-4c32-da10-2d73d1e6bd74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-6515c9a1bc96>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Train the model with fine-tuned weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mhistory_unfreeze\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 128, 128, 3), found shape=(32, 28, 28, 1)\n"]}]}]}